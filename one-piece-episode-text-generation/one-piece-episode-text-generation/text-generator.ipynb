{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text-generator.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WjDVHmGxcwp_","colab_type":"code","outputId":"6540a94a-1d6b-441a-a958-c49c1e3a1c27","executionInfo":{"status":"ok","timestamp":1565272629753,"user_tz":-330,"elapsed":35297,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B-yu1BdacF-8","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/open_ai/one-piece-episode-text-generation')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqpUOynuchH9","colab_type":"code","outputId":"53908ff3-e680-4c0b-ac50-6728a7dc3967","executionInfo":{"status":"ok","timestamp":1565272632758,"user_tz":-330,"elapsed":38258,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UmBNK6lgfkRt","colab_type":"code","colab":{}},"source":["def get_file_content(filename):\n","  try:\n","    text = ''\n","    with open(filename, 'r') as f:\n","      text = f.read().lower()\n","    return text\n","  except:\n","    return ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDOvJh43fk6j","colab_type":"code","colab":{}},"source":["data_dir = 'data'\n","data = ''''''\n","\n","for filename in os.listdir(data_dir):\n","  filepath = os.path.join(data_dir, filename)\n","  data += get_file_content(filepath) + ' '"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3t_ax8OUf220","colab_type":"code","outputId":"7aa9696c-c810-47cf-b131-cb8b5042b15d","executionInfo":{"status":"ok","timestamp":1565162481838,"user_tz":-330,"elapsed":857,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3467335"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"YkCxPSTh9EYY","colab_type":"code","outputId":"8d332c14-3c32-4661-dc75-7b40366a2039","executionInfo":{"status":"ok","timestamp":1565162494900,"user_tz":-330,"elapsed":918,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["data[:1000]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'traveling throughout the world, let us call out in joy. when my heart is rested, the signal to continue is rung. walking the unpaved path in between the sea and the sky. we are now steering our ship. out here in the dark sea, another adventure awaits. i am getting excited just thinking about it. traveling throughout the world, let us call out in joy. when my heart is rested, the signal to continue is rung. the feelings that we had when this adventure just began i hope never to forget. now that i think about it, nothing seems scary to me. with this pace, let us continue this trip. the rhythm of adventure that shy hearted people feel. find all the treasure and laugh out in pride. use it all up during a great party and spray it out! bringing dreams to an empty heart spread your wings take a deep breath and continue on! find all the treasure and laugh out in pride. use it all up during a great party and spray it out! translation and editing: bob timing: shanks wealth fame power the man who'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Fx4Vd8Nhg83S","colab_type":"code","outputId":"0c09aecd-e530-462c-eb28-02eed646ee85","executionInfo":{"status":"ok","timestamp":1565162499612,"user_tz":-330,"elapsed":1401,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["chars = sorted(list(set(data)))\n","chars"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['\\x06',\n"," ' ',\n"," '!',\n"," '\"',\n"," '#',\n"," '$',\n"," '%',\n"," '&',\n"," \"'\",\n"," '(',\n"," ')',\n"," '*',\n"," '+',\n"," ',',\n"," '-',\n"," '.',\n"," '/',\n"," '0',\n"," '1',\n"," '2',\n"," '3',\n"," '4',\n"," '5',\n"," '6',\n"," '7',\n"," '8',\n"," '9',\n"," ':',\n"," ';',\n"," '=',\n"," '>',\n"," '?',\n"," '@',\n"," '[',\n"," '\\\\',\n"," ']',\n"," '^',\n"," '_',\n"," '`',\n"," 'a',\n"," 'b',\n"," 'c',\n"," 'd',\n"," 'e',\n"," 'f',\n"," 'g',\n"," 'h',\n"," 'i',\n"," 'j',\n"," 'k',\n"," 'l',\n"," 'm',\n"," 'n',\n"," 'o',\n"," 'p',\n"," 'q',\n"," 'r',\n"," 's',\n"," 't',\n"," 'u',\n"," 'v',\n"," 'w',\n"," 'x',\n"," 'y',\n"," 'z',\n"," '|',\n"," '~',\n"," '\\x80',\n"," '\\x82',\n"," '\\x85',\n"," '\\x86',\n"," '\\x88',\n"," '\\x89',\n"," '\\x8c',\n"," '\\x8d',\n"," '\\x91',\n"," '\\x93',\n"," '\\x94',\n"," '\\x96',\n"," '\\x97',\n"," '\\x98',\n"," '\\x99',\n"," '\\x9c',\n"," '\\x9d',\n"," '\\xa0',\n"," '¡',\n"," '¥',\n"," '¦',\n"," '¨',\n"," '©',\n"," '¬',\n"," '¯',\n"," '°',\n"," '´',\n"," 'º',\n"," '¼',\n"," 'à',\n"," 'â',\n"," 'ã',\n"," 'ç',\n"," 'è',\n"," 'é',\n"," 'ê',\n"," 'î',\n"," 'ï',\n"," 'ò',\n"," 'ó',\n"," 'ô',\n"," 'ö',\n"," 'û',\n"," 'ü']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"RxlJc013kJAC","colab_type":"code","outputId":"6a89d2b3-642e-44cd-9a7e-d323434477df","executionInfo":{"status":"ok","timestamp":1565162499625,"user_tz":-330,"elapsed":1092,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["chars.index('|')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["65"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"-P4QD3Sxkc5w","colab_type":"code","colab":{}},"source":["chars = chars[:65]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdysKeAPhLqz","colab_type":"code","outputId":"fb84b6a0-0380-479c-9039-e99ad4a70c82","executionInfo":{"status":"ok","timestamp":1565162500460,"user_tz":-330,"elapsed":1402,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["char_to_int = dict((c, i) for i, c in enumerate(chars))\n","char_to_int"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'\\x06': 0,\n"," ' ': 1,\n"," '!': 2,\n"," '\"': 3,\n"," '#': 4,\n"," '$': 5,\n"," '%': 6,\n"," '&': 7,\n"," \"'\": 8,\n"," '(': 9,\n"," ')': 10,\n"," '*': 11,\n"," '+': 12,\n"," ',': 13,\n"," '-': 14,\n"," '.': 15,\n"," '/': 16,\n"," '0': 17,\n"," '1': 18,\n"," '2': 19,\n"," '3': 20,\n"," '4': 21,\n"," '5': 22,\n"," '6': 23,\n"," '7': 24,\n"," '8': 25,\n"," '9': 26,\n"," ':': 27,\n"," ';': 28,\n"," '=': 29,\n"," '>': 30,\n"," '?': 31,\n"," '@': 32,\n"," '[': 33,\n"," '\\\\': 34,\n"," ']': 35,\n"," '^': 36,\n"," '_': 37,\n"," '`': 38,\n"," 'a': 39,\n"," 'b': 40,\n"," 'c': 41,\n"," 'd': 42,\n"," 'e': 43,\n"," 'f': 44,\n"," 'g': 45,\n"," 'h': 46,\n"," 'i': 47,\n"," 'j': 48,\n"," 'k': 49,\n"," 'l': 50,\n"," 'm': 51,\n"," 'n': 52,\n"," 'o': 53,\n"," 'p': 54,\n"," 'q': 55,\n"," 'r': 56,\n"," 's': 57,\n"," 't': 58,\n"," 'u': 59,\n"," 'v': 60,\n"," 'w': 61,\n"," 'x': 62,\n"," 'y': 63,\n"," 'z': 64}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"FZE8WcMRlPMR","colab_type":"code","outputId":"3dcc60c7-b8ef-48e5-f3aa-520568eb30d5","executionInfo":{"status":"ok","timestamp":1565162500462,"user_tz":-330,"elapsed":1295,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["int_to_char = dict((i, c) for c, i in char_to_int.items())\n","int_to_char"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '\\x06',\n"," 1: ' ',\n"," 2: '!',\n"," 3: '\"',\n"," 4: '#',\n"," 5: '$',\n"," 6: '%',\n"," 7: '&',\n"," 8: \"'\",\n"," 9: '(',\n"," 10: ')',\n"," 11: '*',\n"," 12: '+',\n"," 13: ',',\n"," 14: '-',\n"," 15: '.',\n"," 16: '/',\n"," 17: '0',\n"," 18: '1',\n"," 19: '2',\n"," 20: '3',\n"," 21: '4',\n"," 22: '5',\n"," 23: '6',\n"," 24: '7',\n"," 25: '8',\n"," 26: '9',\n"," 27: ':',\n"," 28: ';',\n"," 29: '=',\n"," 30: '>',\n"," 31: '?',\n"," 32: '@',\n"," 33: '[',\n"," 34: '\\\\',\n"," 35: ']',\n"," 36: '^',\n"," 37: '_',\n"," 38: '`',\n"," 39: 'a',\n"," 40: 'b',\n"," 41: 'c',\n"," 42: 'd',\n"," 43: 'e',\n"," 44: 'f',\n"," 45: 'g',\n"," 46: 'h',\n"," 47: 'i',\n"," 48: 'j',\n"," 49: 'k',\n"," 50: 'l',\n"," 51: 'm',\n"," 52: 'n',\n"," 53: 'o',\n"," 54: 'p',\n"," 55: 'q',\n"," 56: 'r',\n"," 57: 's',\n"," 58: 't',\n"," 59: 'u',\n"," 60: 'v',\n"," 61: 'w',\n"," 62: 'x',\n"," 63: 'y',\n"," 64: 'z'}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"qJns8Oockk20","colab_type":"code","colab":{}},"source":["data = [char for char in data if char in chars]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"moBspkUrhh1T","colab_type":"code","outputId":"93762556-866b-4481-94d5-1d918a15fca6","executionInfo":{"status":"ok","timestamp":1565162503138,"user_tz":-330,"elapsed":3363,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["num_chars_in_data = len(data)\n","num_chars_in_vocab = len(chars)\n","\n","print('Total number of characters in data =', num_chars_in_data)\n","print('Total number of characters in vocabulary =', num_chars_in_vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total number of characters in data = 3455602\n","Total number of characters in vocabulary = 65\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yr2LTjB5h9AZ","colab_type":"code","outputId":"4bc1aabb-59ed-420d-c029-73f6f4784fef","executionInfo":{"status":"ok","timestamp":1565162511573,"user_tz":-330,"elapsed":11586,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sequence_length = 200\n","data_x = []\n","data_y = []\n","\n","step_size = 10\n","\n","for i in range(0, num_chars_in_data-sequence_length, step_size):\n","  data_x.append( [char_to_int[char] for char in data[i: i+sequence_length]] )\n","  data_y.append( char_to_int[data[i+sequence_length]] )\n","  \n","num_patterns = len(data_x)\n","print('Total Patterns =', num_patterns)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total Patterns = 345541\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ujgnetGRjY39","colab_type":"code","colab":{}},"source":["def get_senetence_from_list_indexes(list_indexes):\n","  return ''.join([ int_to_char[index] for index in list_indexes ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTWlLjGGlKG0","colab_type":"code","outputId":"b08ea12b-2fd7-46f6-e93e-0723d3665f4b","executionInfo":{"status":"ok","timestamp":1565162511575,"user_tz":-330,"elapsed":10603,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print(get_senetence_from_list_indexes(data_x[111]))\n","print(int_to_char[data_y[111]])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["people from all over the world to go out to sea! my treasure? if you want it, it is yours! search for it. i left everything i had in that place. men, in search of romance, entered the grand line. the \n","w\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pxq5g6ehl0d6","colab_type":"code","colab":{}},"source":["X = np.reshape(data_x, (num_patterns, sequence_length, 1))\n","X = X / float(num_chars_in_vocab)\n","\n","y = np_utils.to_categorical(data_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9EEIzFO3Sqb","colab_type":"code","outputId":"8e67ca8e-5048-4bc8-cf43-e64a12ee0093","executionInfo":{"status":"ok","timestamp":1565162516914,"user_tz":-330,"elapsed":15130,"user":{"displayName":"VAIBHAV GUPTA","photoUrl":"","userId":"09162494126246944728"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["model = Sequential()\n","model.add( LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True) )\n","model.add( Dropout(0.2) )\n","model.add( LSTM(256) )\n","model.add( Dropout(0.2) )\n","model.add( Dense(y.shape[1], activation='softmax') )\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0807 07:21:55.931834 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0807 07:21:55.979270 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0807 07:21:55.987223 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0807 07:21:56.292580 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0807 07:21:56.300781 139858882381696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0807 07:21:56.588324 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0807 07:21:56.610674 139858882381696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9cKbLGkG3rHJ","colab_type":"code","colab":{}},"source":["model_filepath = 'weights_improvement-{epoch:02d}-{loss:.4f}.hdf5'\n","checkpoint = ModelCheckpoint(model_filepath, monitor='loss', verbose=1, save_best_only=True)\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNaZ8a30dljx","colab_type":"code","colab":{}},"source":["model.load_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zocmw8GX4QGs","colab_type":"code","outputId":"40b6ae7c-190b-4794-f1a0-6b16634e115d","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0807 07:21:56.776496 139858882381696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/50\n","345541/345541 [==============================] - 1412s 4ms/step - loss: 2.7632\n","\n","Epoch 00001: loss improved from inf to 2.76315, saving model to weights_improvement-01-2.7632.hdf5\n","Epoch 2/50\n","345541/345541 [==============================] - 1432s 4ms/step - loss: 2.5261\n","\n","Epoch 00002: loss improved from 2.76315 to 2.52611, saving model to weights_improvement-02-2.5261.hdf5\n","Epoch 3/50\n","345541/345541 [==============================] - 1406s 4ms/step - loss: 2.3699\n","\n","Epoch 00003: loss improved from 2.52611 to 2.36989, saving model to weights_improvement-03-2.3699.hdf5\n","Epoch 4/50\n","345541/345541 [==============================] - 1397s 4ms/step - loss: 2.2576\n","\n","Epoch 00004: loss improved from 2.36989 to 2.25756, saving model to weights_improvement-04-2.2576.hdf5\n","Epoch 5/50\n","345541/345541 [==============================] - 1411s 4ms/step - loss: 2.1753\n","\n","Epoch 00005: loss improved from 2.25756 to 2.17530, saving model to weights_improvement-05-2.1753.hdf5\n","Epoch 6/50\n","345541/345541 [==============================] - 1442s 4ms/step - loss: 2.1083\n","\n","Epoch 00006: loss improved from 2.17530 to 2.10832, saving model to weights_improvement-06-2.1083.hdf5\n","Epoch 7/50\n","345541/345541 [==============================] - 1450s 4ms/step - loss: 2.0575\n","\n","Epoch 00007: loss improved from 2.10832 to 2.05752, saving model to weights_improvement-07-2.0575.hdf5\n","Epoch 8/50\n","345541/345541 [==============================] - 1436s 4ms/step - loss: 2.0107\n","\n","Epoch 00008: loss improved from 2.05752 to 2.01067, saving model to weights_improvement-08-2.0107.hdf5\n","Epoch 9/50\n","345541/345541 [==============================] - 1434s 4ms/step - loss: 1.9727\n","\n","Epoch 00009: loss improved from 2.01067 to 1.97274, saving model to weights_improvement-09-1.9727.hdf5\n","Epoch 10/50\n","345541/345541 [==============================] - 1407s 4ms/step - loss: 1.9366\n","\n","Epoch 00010: loss improved from 1.97274 to 1.93661, saving model to weights_improvement-10-1.9366.hdf5\n","Epoch 11/50\n","345541/345541 [==============================] - 1402s 4ms/step - loss: 1.9083\n","\n","Epoch 00011: loss improved from 1.93661 to 1.90830, saving model to weights_improvement-11-1.9083.hdf5\n","Epoch 12/50\n","345541/345541 [==============================] - 1397s 4ms/step - loss: 1.8804\n","\n","Epoch 00012: loss improved from 1.90830 to 1.88040, saving model to weights_improvement-12-1.8804.hdf5\n","Epoch 13/50\n","345541/345541 [==============================] - 1407s 4ms/step - loss: 1.8537\n","\n","Epoch 00013: loss improved from 1.88040 to 1.85370, saving model to weights_improvement-13-1.8537.hdf5\n","Epoch 14/50\n","345541/345541 [==============================] - 1399s 4ms/step - loss: 1.8323\n","\n","Epoch 00014: loss improved from 1.85370 to 1.83233, saving model to weights_improvement-14-1.8323.hdf5\n","Epoch 15/50\n","345541/345541 [==============================] - 1409s 4ms/step - loss: 1.8059\n","\n","Epoch 00015: loss improved from 1.83233 to 1.80587, saving model to weights_improvement-15-1.8059.hdf5\n","Epoch 16/50\n","345541/345541 [==============================] - 1403s 4ms/step - loss: 1.7866\n","\n","Epoch 00016: loss improved from 1.80587 to 1.78657, saving model to weights_improvement-16-1.7866.hdf5\n","Epoch 17/50\n","345541/345541 [==============================] - 1380s 4ms/step - loss: 1.7760\n","\n","Epoch 00017: loss improved from 1.78657 to 1.77597, saving model to weights_improvement-17-1.7760.hdf5\n","Epoch 18/50\n","345541/345541 [==============================] - 1401s 4ms/step - loss: 1.7539\n","\n","Epoch 00018: loss improved from 1.77597 to 1.75390, saving model to weights_improvement-18-1.7539.hdf5\n","Epoch 19/50\n","345541/345541 [==============================] - 1396s 4ms/step - loss: 1.7419\n","\n","Epoch 00019: loss improved from 1.75390 to 1.74186, saving model to weights_improvement-19-1.7419.hdf5\n","Epoch 20/50\n","345541/345541 [==============================] - 1401s 4ms/step - loss: 1.7271\n","\n","Epoch 00020: loss improved from 1.74186 to 1.72705, saving model to weights_improvement-20-1.7271.hdf5\n","Epoch 21/50\n","345541/345541 [==============================] - 1398s 4ms/step - loss: 1.7278\n","\n","Epoch 00021: loss did not improve from 1.72705\n","Epoch 22/50\n","345541/345541 [==============================] - 1401s 4ms/step - loss: 1.7076\n","\n","Epoch 00022: loss improved from 1.72705 to 1.70761, saving model to weights_improvement-22-1.7076.hdf5\n","Epoch 23/50\n","202880/345541 [================>.............] - ETA: 9:39 - loss: 1.6938Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M5M-mTqm9HyW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}